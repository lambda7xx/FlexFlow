+ mpirun --mca btl_tcp_if_exclude lo,docker0 --mca oob_tcp_if_exclude lo,docker0 --map-by ppr:4:node:pe=6 --oversubscribe -H 172.31.4.20 --bind-to core -x OMP_NUM_THREADS=6 /home/lambda/.conda/envs/myenv/bin/python -m flexgen.dist_flex_opt --head-ip 172.31.4.20 --port 7777 --use-mpi --model facebook/opt-6.7b --gpu-batch-size 24 --percent 50 50 0 100 0 100 --comm-device cpu --cut-gen-len 5 --path _DUMMY_
Initializing distributed environment at 172.31.4.20:7777, world_size=4, rank=2, local_rank=2.
Initializing distributed environment at 172.31.4.20:7777, world_size=4, rank=3, local_rank=3.
Initializing distributed environment at 172.31.4.20:7777, world_size=4, rank=0, local_rank=0.
Initializing distributed environment at 172.31.4.20:7777, world_size=4, rank=1, local_rank=1.
rank #0: Finished initializing distributed environment
rank #3: Finished initializing distributed environment
rank #1: Finished initializing distributed environment
rank #2: Finished initializing distributed environment
rank #1: args.offload_dir:~/flexgen_offload_dir
rank #0: args.offload_dir:~/flexgen_offload_dir
rank #2: args.offload_dir:~/flexgen_offload_dir
rank #3: args.offload_dir:~/flexgen_offload_dir
rank #1: model size: 12.386 GB, cache size: 30.000 GB, hidden size (prefill): 0.469 GB
rank #1: warmup - generate
rank #2: model size: 12.386 GB, cache size: 30.000 GB, hidden size (prefill): 0.469 GB
rank #2: warmup - generate
rank #3: model size: 12.386 GB, cache size: 30.000 GB, hidden size (prefill): 0.469 GB
rank #3: warmup - generate
rank #0: model size: 12.386 GB, cache size: 30.000 GB, hidden size (prefill): 0.469 GB
rank #0: warmup - generate
rank #2: args.gen_len:32
rank #2: benchmark - generate
rank #3: args.gen_len:32
rank #3: benchmark - generate
rank #0: args.gen_len:32
rank #0: benchmark - generate
rank #1: args.gen_len:32
rank #1: benchmark - generate
rank #1: duration:24.214675188064575
rank #3: duration:24.215935468673706
rank #2: duration:24.21650767326355
rank #0: duration:24.224737882614136
rank #3: Outputs:
----------------------------------------------------------------------
0: Paris is the capital city of<s><s><s><s><s>
----------------------------------------------------------------------
95: Paris is the capital city of<s><s><s><s><s>
----------------------------------------------------------------------

rank #3: TorchDevice: cuda:3
rank #3:   cur_mem: 1.8840 GB,  peak_mem: 3.7538 GB
rank #3: TorchDevice: cpu
rank #3:   cur_mem: 1.5004 GB,  peak_mem: 0.0000 GB
rank #3: model size: 12.386 GB	cache size: 30.000 GB	hidden size (prefill): 0.469 GB
peak gpu mem: 3.754 GB
prefill latency: 14.32 s	prefill throughput: 3433.15 token/s
decode latency: 300.71 s	decode throughput: 40.54 token/s
total latency: 315.03 s	total throughput: 39.01 token/s
/home/lambda/.local/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:262: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
