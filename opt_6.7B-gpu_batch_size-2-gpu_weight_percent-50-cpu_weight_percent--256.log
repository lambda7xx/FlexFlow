/home/lambda/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:262: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
batch_size: 2 args.overlap: True , args.cut_gen_len: 5
<run_flexgen>: args.model: facebook/opt-6.7b
get_test_inputs, prompt_len:32 and batch_size:2
prompts:['Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.', 'Write a short blog post (500 words) about the best dog toys for new dog owners.']
len(prompt):102
len(prompt):79
input_prompt:102
input_prompt:79
get_test_inputs, prompt_len:64 and batch_size:2
prompts:['Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.', 'Write a short blog post (500 words) about the best dog toys for new dog owners.']
len(prompt):102
len(prompt):79
input_prompt:102
input_prompt:79
model size: 12.386 GB, cache size: 0.312 GB, hidden size (prefill): 0.005 GB
init weight...
warmup - generate
benchmark - generate
decode_costs: [1.1410680839999259, 1.100211826999839, 1.10008460500012, 1.036029736999808]
Outputs:
----------------------------------------------------------------------
0: Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 6.4009 GB,  peak_mem: 7.1624 GB
TorchDevice: cpu
  cur_mem: 6.3850 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.312 GB	hidden size (p): 0.005 GB
peak gpu mem: 7.162 GB	projected: True
prefill latency: 1.102 s	prefill throughput: 116.166 token/s
decode latency: 272.460 s	decode throughput: 1.872 token/s
total latency: 273.562 s	total throughput: 1.872 token/s
