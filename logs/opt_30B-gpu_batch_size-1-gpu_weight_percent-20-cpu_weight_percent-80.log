/home/ubuntu/.local/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:293: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/home/ubuntu/flexgen/flexgen/utils.py:132: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  data_ptr = tensor.storage().data_ptr()
batch_size: 1 args.overlap: True , args.cut_gen_len: 5
<run_flexgen>: args.model: facebook/opt-30b
gen_len:92 and cut_gen_len:5
get_test_inputs, prompt_len:32 and batch_size:1
prompts:['Give three tips for staying healthy.']
len(prompt):36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 31033, 130, 4965, 13, 4959, 2245, 4]]
get_test_inputs, prompt_len:36 and batch_size:1
prompts:['Give three tips for staying healthy.']
len(prompt):36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 31033, 130, 4965, 13, 4959, 2245, 4]]
model size: 55.803 GB, cache size: 0.164 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:98 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:1 and gen_len:92 and decode_latency:376.8165823779891 
Outputs:
----------------------------------------------------------------------
0: Give three tips for staying healthy.
1. Eat healthy. 2. Exercise. 3. Don't be a dick.                                                                          
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 4.6329 GB,  peak_mem: 6.2453 GB
TorchDevice: cpu
  cur_mem: 51.8782 GB,  peak_mem: 0.0000 GB
model size: 55.803 GB	cache size: 0.164 GB	hidden size (p): 0.002 GB
peak gpu mem: 6.245 GB	projected: False
prefill latency: 4.142 s	prefill throughput: 8.692 token/s
decode latency: 376.817 s	decode throughput: 0.241 token/s
total latency: 380.958 s	total throughput: 0.241 token/s
