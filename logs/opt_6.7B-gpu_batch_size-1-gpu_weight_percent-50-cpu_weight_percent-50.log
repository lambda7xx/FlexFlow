/home/lambda/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:262: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
batch_size: 1 args.overlap: True
<run_flexgen>: args.model: facebook/opt-6.7b
get_test_inputs, prompt_len:32 and batch_size:1
prompts:['Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.']
len(prompt):102
input_prompt:102
get_test_inputs, prompt_len:64 and batch_size:1
prompts:['Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.']
len(prompt):102
input_prompt:102
model size: 12.386 GB, cache size: 0.094 GB, hidden size (prefill): 0.001 GB
init weight...
warmup - generate
benchmark - generate
Outputs:
----------------------------------------------------------------------
0: Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.


----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 6.4009 GB,  peak_mem: 6.9445 GB
TorchDevice: cpu
  cur_mem: 6.3850 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.094 GB	hidden size (p): 0.001 GB
peak gpu mem: 6.945 GB	projected: False
prefill latency: 1.100 s	prefill throughput: 58.193 token/s
decode latency: 139.443 s	decode throughput: 0.911 token/s
total latency: 140.542 s	total throughput: 0.911 token/s
