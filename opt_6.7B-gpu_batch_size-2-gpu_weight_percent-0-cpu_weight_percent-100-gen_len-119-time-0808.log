batch_size: 2 args.overlap: True , args.cut_gen_len: 5
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:36 and bs:2
len(prompt):36 and prompt:Give three tips for staying healthy. and batch_size:2
len(prompt):36 and prompt:Give three tips for staying healthy. and batch_size:2
input_prompt:36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 31033, 130, 4965, 13, 4959, 2245, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 31033, 130, 4965, 13, 4959, 2245, 4]]
len(prompt):36 and prompt:Give three tips for staying healthy. and batch_size:2
len(prompt):36 and prompt:Give three tips for staying healthy. and batch_size:2
input_prompt:36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 31033, 130, 4965, 13, 4959, 2245, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 31033, 130, 4965, 13, 4959, 2245, 4]]
model size: 12.386 GB, cache size: 0.150 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.74641114199903 
total_per_token_latency:1.0234850023982955
Outputs:
----------------------------------------------------------------------
0: Give three tips for staying healthy.

1. Eat a healthy diet.

2. Exercise regularly.

3. Get enough sleep.

What is your favorite healthy snack?

I love to eat fresh fruit.

What is your favorite healthy recipe?

I love to make smoothies.

What is your favorite healthy recipe?

I love to make smoothies.

What is your favorite healthy recipe?

I love to make smoothies.

What is your favorite healthy recipe?

I love to make smoothies.

What is
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: Give three tips for staying healthy.

1. Eat a healthy diet.

2. Exercise regularly.

3. Get enough sleep.

What is your favorite healthy snack?

I love to eat fresh fruit.

What is your favorite healthy recipe?

I love to make smoothies.

What is your favorite healthy recipe?

I love to make smoothies.

What is your favorite healthy recipe?

I love to make smoothies.

What is your favorite healthy recipe?

I love to make smoothies.

What is
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9534 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.150 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.953 GB	projected: False
prefill latency: 1.025 s	prefill throughput: 70.256 token/s
decode latency: 119.746 s	decode throughput: 1.954 token/s
total latency: 120.771 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:29 and bs:2
len(prompt):29 and prompt:I ran out of patience for him and batch_size:2
len(prompt):29 and prompt:I ran out of patience for him and batch_size:2
input_prompt:29
input_prompt:29
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 2075, 66, 9, 11383, 13, 123], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 2075, 66, 9, 11383, 13, 123]]
len(prompt):29 and prompt:I ran out of patience for him and batch_size:2
len(prompt):29 and prompt:I ran out of patience for him and batch_size:2
input_prompt:29
input_prompt:29
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 2075, 66, 9, 11383, 13, 123], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 2075, 66, 9, 11383, 13, 123]]
model size: 12.386 GB, cache size: 0.144 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.74102313199592 
total_per_token_latency:2.046916364677921
Outputs:
----------------------------------------------------------------------
0: I ran out of patience for him after the first episode.
I'm with you. I'm not a fan of the show, but I'm not going to bash it. I just don't like it. I don't think it's funny. I don't think it's interesting. I don't think it's well written. I don't think it's well acted. I don't think it's well directed. I don't think it's well produced. I don't think it's well edited. I don't think it's well produced.
I think it's well produced. I think it's
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: I ran out of patience for him after the first episode.
I'm with you. I'm not a fan of the show, but I'm not going to bash it. I just don't like it. I don't think it's funny. I don't think it's interesting. I don't think it's well written. I don't think it's well acted. I don't think it's well directed. I don't think it's well produced. I don't think it's well edited. I don't think it's well produced.
I think it's well produced. I think it's
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9534 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.144 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.953 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 56.647 token/s
decode latency: 119.741 s	decode throughput: 1.954 token/s
total latency: 120.765 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:36 and bs:2
len(prompt):36 and prompt:What are the symptoms of depression? and batch_size:2
len(prompt):36 and prompt:What are the symptoms of depression? and batch_size:2
input_prompt:36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 32, 5, 5298, 9, 6943, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 32, 5, 5298, 9, 6943, 116]]
len(prompt):36 and prompt:What are the symptoms of depression? and batch_size:2
len(prompt):36 and prompt:What are the symptoms of depression? and batch_size:2
input_prompt:36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 32, 5, 5298, 9, 6943, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 32, 5, 5298, 9, 6943, 116]]
model size: 12.386 GB, cache size: 0.150 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.742224953 
total_per_token_latency:3.070357004160975
Outputs:
----------------------------------------------------------------------
0: What are the symptoms of depression?

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more than 300 million people worldwide.

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more than 300 million people worldwide.

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more than 300 million people worldwide.

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: What are the symptoms of depression?

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more than 300 million people worldwide.

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more than 300 million people worldwide.

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more than 300 million people worldwide.

Depression is a serious mental illness that can affect anyone at any age. It is a common problem that affects more
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9534 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.150 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.953 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 70.328 token/s
decode latency: 119.742 s	decode throughput: 1.954 token/s
total latency: 120.766 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:36 and bs:2
len(prompt):36 and prompt:How can I lower my monthly expenses. and batch_size:2
len(prompt):36 and prompt:How can I lower my monthly expenses. and batch_size:2
input_prompt:36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 6179, 64, 38, 795, 127, 3708, 4068, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 6179, 64, 38, 795, 127, 3708, 4068, 4]]
len(prompt):36 and prompt:How can I lower my monthly expenses. and batch_size:2
len(prompt):36 and prompt:How can I lower my monthly expenses. and batch_size:2
input_prompt:36
input_prompt:36
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 6179, 64, 38, 795, 127, 3708, 4068, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 6179, 64, 38, 795, 127, 3708, 4068, 4]]
model size: 12.386 GB, cache size: 0.150 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.75787432500101 
total_per_token_latency:4.093932182813527
Outputs:
----------------------------------------------------------------------
0: How can I lower my monthly expenses. I'm currently paying $1,000 a month for rent, utilities, and food. I'm a student and I'm not making much money. I'm also paying for a car. I'm not sure how to lower my expenses.
You can't lower your expenses. You can only increase your income.
I'm trying to increase my income. I'm a student and I'm not making much money. I'm also paying for a car. I'm not sure how to lower my expenses.
You can't lower your expenses. You can only increase your income.

----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: How can I lower my monthly expenses. I'm currently paying $1,000 a month for rent, utilities, and food. I'm a student and I'm not making much money. I'm also paying for a car. I'm not sure how to lower my expenses.
You can't lower your expenses. You can only increase your income.
I'm trying to increase my income. I'm a student and I'm not making much money. I'm also paying for a car. I'm not sure how to lower my expenses.
You can't lower your expenses. You can only increase your income.

----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9534 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.150 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.953 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 70.313 token/s
decode latency: 119.758 s	decode throughput: 1.954 token/s
total latency: 120.782 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:26 and bs:2
len(prompt):26 and prompt:I want to trick the buyer. and batch_size:2
len(prompt):26 and prompt:I want to trick the buyer. and batch_size:2
input_prompt:26
input_prompt:26
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 236, 7, 7610, 5, 9790, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 236, 7, 7610, 5, 9790, 4]]
len(prompt):26 and prompt:I want to trick the buyer. and batch_size:2
len(prompt):26 and prompt:I want to trick the buyer. and batch_size:2
input_prompt:26
input_prompt:26
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 236, 7, 7610, 5, 9790, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 100, 236, 7, 7610, 5, 9790, 4]]
model size: 12.386 GB, cache size: 0.141 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.74227933499924 
total_per_token_latency:5.117381472194875
Outputs:
----------------------------------------------------------------------
0: I want to trick the buyer. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: I want to trick the buyer. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I want to make them think they are getting a great deal. I
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9534 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.141 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.953 GB	projected: False
prefill latency: 1.025 s	prefill throughput: 50.745 token/s
decode latency: 119.742 s	decode throughput: 1.954 token/s
total latency: 120.767 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:45 and bs:2
len(prompt):45 and prompt:What is the best way to save money on travel. and batch_size:2
len(prompt):45 and prompt:What is the best way to save money on travel. and batch_size:2
input_prompt:45
input_prompt:45
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 275, 169, 7, 1871, 418, 15, 1504, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 275, 169, 7, 1871, 418, 15, 1504, 4]]
len(prompt):45 and prompt:What is the best way to save money on travel. and batch_size:2
len(prompt):45 and prompt:What is the best way to save money on travel. and batch_size:2
input_prompt:45
input_prompt:45
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 275, 169, 7, 1871, 418, 15, 1504, 4], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 275, 169, 7, 1871, 418, 15, 1504, 4]]
model size: 12.386 GB, cache size: 0.159 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.7590904059989 
total_per_token_latency:6.140968049160968
Outputs:
----------------------------------------------------------------------
0: What is the best way to save money on travel. I'm a student and I'm trying to save money for a trip to Europe next year.
I'm a student too and I've found that the best way to save money is to not go on trips.
I'm a student too and I've found that the best way to save money is to not go on trips.                                                   
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: What is the best way to save money on travel. I'm a student and I'm trying to save money for a trip to Europe next year.
I'm a student too and I've found that the best way to save money is to not go on trips.
I'm a student too and I've found that the best way to save money is to not go on trips.                                                   
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9580 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.159 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.958 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 87.880 token/s
decode latency: 119.759 s	decode throughput: 1.954 token/s
total latency: 120.783 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:41 and bs:2
len(prompt):41 and prompt:Which type of yoga is best for beginners? and batch_size:2
len(prompt):41 and prompt:Which type of yoga is best for beginners? and batch_size:2
input_prompt:41
input_prompt:41
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 32251, 1907, 9, 11025, 16, 275, 13, 34476, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 32251, 1907, 9, 11025, 16, 275, 13, 34476, 116]]
len(prompt):41 and prompt:Which type of yoga is best for beginners? and batch_size:2
len(prompt):41 and prompt:Which type of yoga is best for beginners? and batch_size:2
input_prompt:41
input_prompt:41
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 32251, 1907, 9, 11025, 16, 275, 13, 34476, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 32251, 1907, 9, 11025, 16, 275, 13, 34476, 116]]
model size: 12.386 GB, cache size: 0.155 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.75942038900257 
total_per_token_latency:7.16455646856777
Outputs:
----------------------------------------------------------------------
0: Which type of yoga is best for beginners?

There are many types of yoga, and each one has its own benefits. The most popular types of yoga are Hatha yoga, Ashtanga yoga, and Vinyasa yoga.

Hatha yoga is a type of yoga that focuses on the physical body. It is a gentle, slow-paced practice that is designed to help you relax and improve your flexibility.

Ashtanga yoga is a type of yoga that focuses on the breath. It is a fast-paced practice that is designed to help you increase your strength and flexibility.

Vinyasa
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: Which type of yoga is best for beginners?

There are many types of yoga, and each one has its own benefits. The most popular types of yoga are Hatha yoga, Ashtanga yoga, and Vinyasa yoga.

Hatha yoga is a type of yoga that focuses on the physical body. It is a gentle, slow-paced practice that is designed to help you relax and improve your flexibility.

Ashtanga yoga is a type of yoga that focuses on the breath. It is a fast-paced practice that is designed to help you increase your strength and flexibility.

Vinyasa
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9580 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.155 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.958 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 80.077 token/s
decode latency: 119.759 s	decode throughput: 1.954 token/s
total latency: 120.783 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:44 and bs:2
len(prompt):44 and prompt:Show how to add a backround color to a text  and batch_size:2
len(prompt):44 and prompt:Show how to add a backround color to a text  and batch_size:2
input_prompt:44
input_prompt:44
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 27477, 141, 7, 1606, 10, 124, 3431, 3195, 7, 10, 2788, 1437], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 27477, 141, 7, 1606, 10, 124, 3431, 3195, 7, 10, 2788, 1437]]
len(prompt):44 and prompt:Show how to add a backround color to a text  and batch_size:2
len(prompt):44 and prompt:Show how to add a backround color to a text  and batch_size:2
input_prompt:44
input_prompt:44
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 27477, 141, 7, 1606, 10, 124, 3431, 3195, 7, 10, 2788, 1437], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 27477, 141, 7, 1606, 10, 124, 3431, 3195, 7, 10, 2788, 1437]]
model size: 12.386 GB, cache size: 0.158 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.75828976000184 
total_per_token_latency:8.188135835101685
Outputs:
----------------------------------------------------------------------
0: Show how to add a backround color to a text 
I'm not sure if this is the right place to ask this, but I'm having trouble with this. I'm trying to add a background color to a text, but I'm not sure how to do it. I've tried using the following code, but it doesn't seem to work.
<div class="text-background">
<div class="text-color">
<div class="text-background-color">
</div>
</div>
<div class="text-background">
<div class="text-color">
<
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: Show how to add a backround color to a text 
I'm not sure if this is the right place to ask this, but I'm having trouble with this. I'm trying to add a background color to a text, but I'm not sure how to do it. I've tried using the following code, but it doesn't seem to work.
<div class="text-background">
<div class="text-color">
<div class="text-background-color">
</div>
</div>
<div class="text-background">
<div class="text-color">
<
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9580 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.158 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.958 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 85.931 token/s
decode latency: 119.758 s	decode throughput: 1.954 token/s
total latency: 120.782 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:37 and bs:2
len(prompt):37 and prompt:Where can I buy the newest projector? and batch_size:2
len(prompt):37 and prompt:Where can I buy the newest projector? and batch_size:2
input_prompt:37
input_prompt:37
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 13841, 64, 38, 907, 5, 8946, 35282, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 13841, 64, 38, 907, 5, 8946, 35282, 116]]
len(prompt):37 and prompt:Where can I buy the newest projector? and batch_size:2
len(prompt):37 and prompt:Where can I buy the newest projector? and batch_size:2
input_prompt:37
input_prompt:37
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 13841, 64, 38, 907, 5, 8946, 35282, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 13841, 64, 38, 907, 5, 8946, 35282, 116]]
model size: 12.386 GB, cache size: 0.151 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
/home/ubuntu/.local/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:293: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/home/ubuntu/flexgen/flexgen/utils.py:132: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  data_ptr = tensor.storage().data_ptr()
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.74308018600186 
total_per_token_latency:9.211583921500006
Outputs:
----------------------------------------------------------------------
0: Where can I buy the newest projector?

A:

Quick Answer

The newest projector is the Optoma HD20, which was released in 2015. The Optoma HD20 is a 1080p projector that has a resolution of 1920 x 1080 pixels. The projector has a brightness of 2,000 lumens and a contrast ratio of 1,000,000:1.

Keep Learning

The Optoma HD20 has a native resolution of 1920 x 1080 pixels, which is the same resolution as the Apple Retina Display. The projector has a contrast ratio of 1,000,000:1,
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: Where can I buy the newest projector?

A:

Quick Answer

The newest projector is the Optoma HD20, which was released in 2015. The Optoma HD20 is a 1080p projector that has a resolution of 1920 x 1080 pixels. The projector has a brightness of 2,000 lumens and a contrast ratio of 1,000,000:1.

Keep Learning

The Optoma HD20 has a native resolution of 1920 x 1080 pixels, which is the same resolution as the Apple Retina Display. The projector has a contrast ratio of 1,000,000:1,
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9580 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.151 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.958 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 72.280 token/s
decode latency: 119.743 s	decode throughput: 1.954 token/s
total latency: 120.767 s	total throughput: 1.954 token/s
<run_flexgen>: args.model: facebook/opt-6.7b
gen_len:118 and cut_gen_len:5 and prompt_len:32 and bs:2
len(prompt):32 and prompt:What is the history of Beyblade? and batch_size:2
len(prompt):32 and prompt:What is the history of Beyblade? and batch_size:2
input_prompt:32
input_prompt:32
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 750, 9, 1456, 219, 41469, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 750, 9, 1456, 219, 41469, 116]]
len(prompt):32 and prompt:What is the history of Beyblade? and batch_size:2
len(prompt):32 and prompt:What is the history of Beyblade? and batch_size:2
input_prompt:32
input_prompt:32
input_ids:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 750, 9, 1456, 219, 41469, 116], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2264, 16, 5, 750, 9, 1456, 219, 41469, 116]]
model size: 12.386 GB, cache size: 0.146 GB, hidden size (prefill): 0.002 GB
init weight...
num_layers:66 and num_gpu_batches:1
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
dtype:<class 'numpy.float16'>
warmup - generate
benchmark - generate
num_prompts:2 and gen_len:118 and decode_latency:119.75913607200255 
total_per_token_latency:10.235169898305113
Outputs:
----------------------------------------------------------------------
0: What is the history of Beyblade?

Beyblade is a Japanese toy that was first introduced in 1999. It is a toy that is played with by spinning a metal blade. The toy is popular in Japan and has been exported to other countries.

The toy was created by a Japanese toy company called Bandai. The toy was first introduced in 1999 and has been a hit ever since. The toy is popular in Japan and has been exported to other countries.

The toy is played with by spinning a metal blade. The toy is popular in Japan and has been exported to other countries.

The toy
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: What is the history of Beyblade?

Beyblade is a Japanese toy that was first introduced in 1999. It is a toy that is played with by spinning a metal blade. The toy is popular in Japan and has been exported to other countries.

The toy was created by a Japanese toy company called Bandai. The toy was first introduced in 1999 and has been a hit ever since. The toy is popular in Japan and has been exported to other countries.

The toy is played with by spinning a metal blade. The toy is popular in Japan and has been exported to other countries.

The toy
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 0.0079 GB,  peak_mem: 0.9580 GB
TorchDevice: cpu
  cur_mem: 12.7859 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.146 GB	hidden size (p): 0.002 GB
peak gpu mem: 0.958 GB	projected: False
prefill latency: 1.024 s	prefill throughput: 62.499 token/s
decode latency: 119.759 s	decode throughput: 1.954 token/s
total latency: 120.783 s	total throughput: 1.954 token/s
per token latency:1.0235169898305112
