/home/lambda/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:262: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
batch_size: 2 args.overlap: True , args.cut_gen_len: 5
<run_flexgen>: args.model: facebook/opt-30b
get_test_inputs, prompt_len:32 and batch_size:2
prompts:['Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.', 'Write a short blog post (500 words) about the best dog toys for new dog owners.']
len(prompt):102
len(prompt):79
input_prompt:102
input_prompt:79
get_test_inputs, prompt_len:64 and batch_size:2
prompts:['Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.', 'Write a short blog post (500 words) about the best dog toys for new dog owners.']
len(prompt):102
len(prompt):79
input_prompt:102
input_prompt:79
model size: 55.803 GB, cache size: 0.492 GB, hidden size (prefill): 0.005 GB
init weight...
warmup - generate
benchmark - generate
decode_costs: [8.903729997999108, 8.891630316000374, 8.890961566999977, 8.779070519000015]
Outputs:
----------------------------------------------------------------------
0: Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

The food cho
----------------------------------------------------------------------

Outputs:
----------------------------------------------------------------------
1: Write a detailed product description for a food chopper tool that lets you chop fruits and vegetables.

The food cho
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 4.6250 GB,  peak_mem: 6.5684 GB
TorchDevice: cpu
  cur_mem: 51.8782 GB,  peak_mem: 0.0000 GB
model size: 55.803 GB	cache size: 0.492 GB	hidden size (p): 0.005 GB
peak gpu mem: 6.568 GB	projected: True
prefill latency: 8.894 s	prefill throughput: 14.392 token/s
decode latency: 1122.172 s	decode throughput: 0.226 token/s
total latency: 1131.066 s	total throughput: 0.226 token/s
